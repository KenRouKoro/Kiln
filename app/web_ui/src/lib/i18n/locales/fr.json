{
  "common": {
    "save": "Enregistrer",
    "cancel": "Annuler",
    "delete": "Supprimer",
    "edit": "Modifier",
    "create": "Créer",
    "update": "Mettre à jour",
    "close": "Fermer",
    "continue": "Continuer",
    "retry": "Réessayer",
    "loading": "Chargement...",
    "error": "Erreur",
    "success": "Succès",
    "warning": "Avertissement",
    "info": "Info",
    "yes": "Oui",
    "no": "Non",
    "ok": "OK",
    "back": "Retour",
    "next": "Suivant",
    "previous": "Précédent",
    "submit": "Soumettre",
    "reset": "Réinitialiser",
    "clear": "Effacer",
    "search": "Rechercher",
    "filter": "Filtrer",
    "sort": "Trier",
    "export": "Exporter",
    "import": "Importer",
    "download": "Télécharger",
    "upload": "Téléverser",
    "view": "Voir",
    "add": "Ajouter",
    "remove": "Retirer",
    "copy": "Copier",
    "paste": "Coller",
    "cut": "Couper",
    "select": "Sélectionner",
    "all": "Tous",
    "none": "Aucun",
    "refresh": "Actualiser",
    "reload": "Recharger",
    "back_home": "Retour à l'accueil",
    "change": "Modifier",
    "accept": "Accepter",
    "reject": "Rejeter",
    "show": "Afficher",
    "hide": "Masquer",
    "version": "Version",
    "tags": "Étiquettes",
    "or": "Ou",
    "has": "a",
    "samples": "échantillons",
    "before_you_start": "avant de commencer",
    "id": "ID",
    "recommended": "Recommandé",
    "and": " et ",
    "task": "Tâche"
  },
  "navigation": {
    "run": "Exécuter",
    "dataset": "Jeu de données",
    "synthetic_data": "Données synthétiques",
    "fine_tune": "Ajustement fin",
    "evals": "Évaluations",
    "prompts": "Invites",
    "settings": "Paramètres"
  },
  "project": {
    "name": "Nom du projet",
    "description": "Description du projet",
    "create_project": "Créer un projet",
    "add_project": "Ajouter un projet",
    "add_project_subtitle": "Les projets regroupent des tâches, résultats, évaluations et autres ressources.",
    "edit_project": "Modifier le projet",
    "manage_projects": "Gérer les projets",
    "manage_projects_subtitle": "Ajouter ou supprimer des projets",
    "project_created": "Projet créé !",
    "project_imported": "Projet importé !",
    "import_project": "Importer un projet",
    "existing_project_path": "Chemin du projet existant",
    "import_existing_project": "importer un projet existant",
    "create_new_project": "créer un nouveau projet",
    "update_project": "Mettre à jour le projet",
    "project_created_message": "Votre nouveau projet \"{name}\" a été créé.",
    "project_imported_message": "Votre projet \"{path}\" a été importé.",
    "project_path_description": "Chemin local du projet. Ex: /Users/utilisateur/Projets Kiln/mon_projet/project.kiln",
    "add_task": "Ajouter une tâche",
    "current": "Actuel",
    "no_projects_found": "Aucun projet trouvé",
    "remove_project_confirm": "Confirmez-vous la suppression du projet \"{name}\"?\n\nCela le retirera de l'interface sans supprimer les fichiers de votre disque.",
    "failed_to_remove_project": "Échec de suppression du projet.\n\nRaison : {error}",
    "create_project_subtitle": "\"Exemple\" convient pour les tests.",
    "just_exploring": "Vous explorez ?",
    "create_example": "Créer un exemple",
    "example_project_name": "Projet Exemple",
    "example_project_description": "Exemple de projet pour tester les fonctionnalités."
  },
  "task": {
    "name": "Nom de la tâche",
    "description": "Description de la tâche",
    "instructions": "Instructions de la tâche",
    "create_task": "Créer une tâche",
    "new_task": "Nouvelle tâche",
    "new_task_description": "Une 'tâche' est un objectif unique pour un modèle.",
    "target_project": "Projet cible",
    "edit_task": "Modifier la tâche",
    "clone_task": "Cloner la tâche",
    "clone_task_subtitle": "Créer une nouvelle tâche basée sur un modèle existant",
    "clone_task_description": "La tâche clonée ne contiendra aucune donnée de l'originale.",
    "current_task": "Tâche actuelle",
    "select_task": "Sélectionner une tâche",
    "task_created": "Tâche créée !",
    "prompt_description": "L'invite que le modèle doit suivre.",
    "task_id": "ID de tâche",
    "error_loading_task": "Erreur de chargement de la tâche",
    "task_access_error": "Tâche inaccessible. Projet non autorisé.",
    "project_or_task_id_missing": "ID de projet ou tâche manquant.",
    "copy_of": "Copie de {name}",
    "schema_section": {
      "plain_text": "Texte brut",
      "structured_json": "JSON structuré"
    },
    "create_task_page": {
      "title": "Créer une tâche",
      "subtitle": "Définissons ce que le modèle doit faire. Nous appelons cela une \"tâche\"."
    },
    "edit_task_page": {
      "part_1_overview": "Partie 1 : Aperçu",
      "just_exploring": "Vous explorez ?",
      "try_example": "Essayer un exemple.",
      "task_name_label": "Nom de la tâche",
      "task_name_description": "Descriptif pour vous/votre équipe (non utilisé par le modèle).",
      "prompt_task_instructions_label": "Invite / Instructions de tâche",
      "task_description_label": "Description de la tâche",
      "task_description_description": "Descriptif pour vous/votre équipe (non utilisé par le modèle).",
      "thinking_instructions_label": "Instructions de 'réflexion'",
      "thinking_instructions_description": "Instructions pour la réflexion du modèle avant réponse (chaîne de raisonnement).",
      "thinking_instructions_info": "Utilisé pour les invites 'Chaîne de raisonnement'. Si vide, une invite par défaut sera utilisée.",
      "part_2_requirements": "Partie 2 : Exigences",
      "requirements_description": "Définissez des exigences pour évaluer les résultats du modèle.",
      "learn_more": "En savoir plus",
      "requirement_name_label": "Nom de l'exigence",
      "requirement_name_info": "Nom court identifiant l'exigence (affiché dans l'interface d'évaluation).",
      "rating_type_label": "Type d'évaluation",
      "priority_label": "Priorité",
      "requirement_instructions_label": "Instructions : phrases décrivant cette exigence pour le modèle",
      "requirement_instructions_info": "Ces instructions seront ajoutées à l'invite et utilisées dans les évaluations.",
      "input_schema_title": "Schéma d'entrée",
      "output_schema_title": "Schéma de sortie",
      "input_schema_description": "Quel type d'entrée le modèle recevra-t-il ?",
      "output_schema_description": "Quel type de sortie le modèle produira-t-il ?",
      "cannot_edit_existing_schema": "Impossible de modifier le format {type} d'une tâche existante.",
      "clone_task_instead": "Vous pouvez",
      "clone_this_task": "cloner cette tâche",
      "instead": "à la place.",
      "save_task": "Enregistrer la tâche",
      "create_task": "Créer la tâche",
      "replace_edits_confirm": "Cela remplacera vos modifications actuelles. Confirmez-vous ?",
      "example_task_name": "Générateur de blagues",
      "example_task_description": "Exemple de tâche de l'équipe KilnAI.",
      "example_task_instruction": "Générer une blague sur un thème donné. Le thème est fourni comme entrée. La sortie doit inclure une accroche et une chute.",
      "prompt_description_editing_with_requirements": "Invite de base utilisée par les générateurs d'invites (Basique, Multi-exemples, etc.).",
      "prompt_description_editing_no_requirements": "Invite de base utilisée par les générateurs d'invites.",
      "prompt_description_creating": "L'invite que le modèle doit suivre.",
      "rating_types": {
        "five_star": "5 étoiles",
        "pass_fail": "Réussi/Échoué",
        "pass_fail_critical": "Réussi/Échoué/Critique"
      },
      "priorities": {
        "p0_critical": "P0 - Critique",
        "p1_high": "P1 - Élevée",
        "p2_medium": "P2 - Moyenne",
        "p3_low": "P3 - Faible"
      },
      "input_format_plain_text": "Format d'entrée : Texte brut",
      "output_format_plain_text": "Format de sortie : Texte brut",
      "part": "Partie",
      "project_required_error": "Créez d'abord un projet",
      "current_project_not_found": "Projet actuel introuvable",
      "requirement_label": "Exigence",
      "example_joke_topic_title": "Thème de la blague",
      "example_joke_topic_description": "Thème de la blague.",
      "example_joke_style_title": "Style de blague",
      "example_joke_style_description": "Style comme 'blague de papa' ou 'pour enfants'.",
      "example_setup_title": "accroche",
      "example_setup_description": "L'accroche de la blague",
      "example_punchline_title": "chute",
      "example_punchline_description": "La chute de la blague",
      "project_id_prefix": "ID du projet : "
    }
  },
  "settings": {
    "title": "Paramètres",
    "edit_task": "Modifier la tâche",
    "edit_task_description": "Modifier la tâche actuelle, y compris l'invite et les exigences.",
    "edit_current_task": "Modifier la tâche actuelle",
    "ai_providers": "Fournisseurs d'IA & Modèles",
    "ai_providers_description": "Connectez des clés API (OpenAI, OpenRouter, Ollama).",
    "read_the_docs": "Lire la documentation",
    "manage_providers": "Gérer les fournisseurs & modèles",
    "manage_projects_description": "Ajouter, supprimer ou modifier des projets.",
    "edit_project_description": "Modifier le projet actuellement sélectionné.",
    "edit_current_project": "Modifier le projet actuel",
    "app_updates": "Mises à jour de l'application",
    "app_updates_description": "Vérifier les nouvelles versions disponibles.",
    "check_for_update": "Vérifier les mises à jour",
    "replay_introduction": "Revoir l'introduction",
    "replay_intro_description": "Revivre la présentation d'introduction.",
    "play_intro": "Lancer l'intro",
    "license": "Licence",
    "license_description": "Voir le contrat de licence de Kiln AI.",
    "view_eula": "Voir le CLUF",
    "language": "Langue",
    "language_description": "Modifier la langue de l'application."
  },
  "dataset": {
    "title": "Jeu de données",
    "read_the_docs": "Lire la documentation",
    "add_data": "Ajouter des données",
    "view_dataset": "Voir le jeu de données",
    "data_added": "Données ajoutées",
    "data_added_subtitle": "Vos données ont été ajoutées.",
    "manually_tag_existing_data": "Étiqueter manuellement des données existantes",
    "open_dataset": "Ouvrir le jeu de données",
    "error_loading": "Erreur de chargement du jeu de données",
    "filter_by_tags": "Filtrer le jeu de données par étiquettes",
    "current_filters": "Filtres actuels :",
    "add_filter": "Ajouter un filtre :",
    "no_more_filters": "Tout filtre supplémentaire donnera zéro résultat.",
    "delete_runs": "Supprimer des exécutions",
    "delete_run": "Supprimer l'exécution",
    "cannot_undo": "Action irréversible.",
    "add_tags_to_runs": "Ajouter des étiquettes aux exécutions",
    "add_tags_to_run": "Ajouter des étiquettes à l'exécution",
    "tags_organize": "Les étiquettes organisent votre jeu de données.",
    "remove_tags_from_runs": "Retirer des étiquettes des exécutions",
    "remove_tags_from_run": "Retirer des étiquettes de l'exécution",
    "selected_tags_remove": "Étiquettes sélectionnées à retirer :",
    "no_tags_selected": "Aucune étiquette sélectionnée.",
    "available_tags": "Étiquettes disponibles :",
    "no_tags_on_runs": "Aucune étiquette sur les exécutions sélectionnées.",
    "all_tags_selected": "Toutes les étiquettes disponibles sont déjà sélectionnées.",
    "rating": "Évaluation",
    "repair_state": "État de réparation",
    "source": "Source",
    "model": "Modèle",
    "created_at": "Créé le",
    "input_preview": "Aperçu de l'entrée",
    "output_preview": "Aperçu de la sortie",
    "no_input": "Aucune entrée",
    "no_output": "Aucune sortie",
    "empty_dataset_title": "Votre jeu de données est vide pour cette tâche.",
    "empty_dataset_description": "Ajoutez des données pour améliorer le modèle.",
    "empty_dataset_instruction": "Commencez par générer des données synthétiques ou ajoutez des données manuellement.",
    "manually_add_data": "Ajouter des données manuellement",
    "generate_synthetic_data": "Générer des données synthétiques",
    "run_title": "Exécution du jeu de données",
    "run_id": "ID d'exécution",
    "run_deleted": "Exécution supprimée",
    "run_not_found": "Exécution introuvable",
    "input": "Entrée",
    "parameters": "Paramètres",
    "input_source": "Source d'entrée",
    "output_model": "Modèle de sortie",
    "model_provider": "Fournisseur du modèle",
    "prompt": "Invite",
    "cost": "Coût",
    "tokens": "Jetons",
    "created_by": "Créé par",
    "topic": "Sujet",
    "could_not_load_run": "Exécution inaccessible. Projet non autorisé.",
    "upload_dialog": {
      "title": "Téléverser un CSV vers le jeu de données",
      "description": "Téléversez un CSV pour ajouter chaque ligne à votre jeu de données. Le CSV doit avoir une ligne d'en-tête.",
      "see_docs": "voir la documentation",
      "supported_columns": "Colonnes supportées :",
      "input_required": "Obligatoire",
      "output_required": "Obligatoire",
      "reasoning_optional": "Optionnel",
      "chain_of_thought_optional": "Optionnel",
      "tags_optional": "Optionnel, chaîne séparée par des virgules"
    }
  },
  "run": {
    "title": "Exécuter",
    "input": "Entrée",
    "options": "Options",
    "clear_all": "Tout effacer",
    "next_run": "Exécution suivante",
    "task_prefix": "Tâche : ",
    "required": "Obligatoire",
    "model_selection_error": "Sélectionnez un modèle avant d'exécuter.",
    "choose_prompt_description": "Choisissez une invite. Voir l'onglet 'Invites'.",
    "output_rating": "Évaluation de la sortie",
    "overall_rating": "Évaluation globale :",
    "edit": "Modifier",
    "retry_repair": "Réessayer la réparation",
    "accept_repair": "Accepter la réparation (5 étoiles)",
    "error_accepting_repair": "Erreur d'acceptation de la réparation",
    "manual_repair": "Réparation manuelle",
    "manual_repair_description": "Améliorez ou corrigez la sortie de la tâche",
    "save_repair": "Enregistrer la réparation (5 étoiles)",
    "error_saving_repair": "Erreur d'enregistrement de la réparation",
    "prompt_method": "Méthode d'invite",
    "prompt_generators": "Générateurs d'invites",
    "fine_tune_prompt": "Invite d'ajustement fin",
    "fine_tune_specific_prompt": "Invite spécifique d'ajustement fin",
    "fine_tune_prompt_description": "Recommandé : Invite utilisée pour l'ajustement fin.",
    "custom_prompt": "Invite personnalisée",
    "saved_prompts": "Invites enregistrées",
    "fine_tune_model_warning": "Utilisez l'invite avec laquelle le modèle a été entraîné pour les modèles ajustés.",
    "plaintext_input": "Entrée en texte brut",
    "invalid_unsupported_schema": "Schéma d'entrée non valide ou non supporté",
    "output": "Sortie",
    "structure_valid": "Structure valide",
    "show_raw_data": "Afficher les données brutes",
    "hide_raw_data": "Masquer les données brutes",
    "raw_data": "Données brutes",
    "repair_output": "Réparer la sortie",
    "repair_not_available": "Réparation indisponible pour les sources {source}.",
    "repair_instructions": "Instructions de réparation",
    "repair_instructions_description": "Instructions pour corriger la sortie (si < 5 étoiles).",
    "attempt_repair": "Tenter la réparation",
    "manual_edit_description": "Améliorer ou corriger manuellement la réponse.",
    "repair_review_description": "Le modèle a tenté de corriger la sortie. Vérifiez le résultat.",
    "your_instructions": "vos instructions",
    "no_instruction_provided": "Aucune instruction fournie",
    "repair_complete_user": "Cette sortie réparée a été fournie par {name}.",
    "repair_complete_model": "Le modèle a corrigé la sortie selon vos instructions.",
    "delete_repair": "Supprimer la réparation",
    "error_deleting_repair": "Erreur de suppression de la réparation :",
    "delete_repair_confirm": "Confirmez-vous la suppression de cette réparation ?\n\nAction irréversible.",
    "intermediate_outputs": {
      "reasoning": "Raisonnement du modèle",
      "chain_of_thought": "Sortie de chaîne de raisonnement"
    },
    "intermediate_output_tooltip": "Sortie intermédiaire du modèle (non incluse dans la réponse finale).",
    "type_descriptions": {
      "string": "Chaîne",
      "number": "Nombre",
      "integer": "Entier",
      "boolean": "'vrai' ou 'faux'",
      "array": "Tableau JSON",
      "object": "Objet JSON",
      "unknown": "Type inconnu",
      "required_suffix": " (obligatoire)",
      "optional_suffix": " (optionnel)"
    },
    "input_info": {
      "array_description": "Liste d'éléments au format JSON. Ex: [élément_1, élément_2]",
      "object_description": "Objet JSON. Ex: {\"clé_1\": \"valeur_1\", \"clé_2\": \"valeur_2\"}"
    }
  },
  "generate": {
    "title": "Générer",
    "no_items_to_save": "Aucun élément à enregistrer",
    "generate_data_to_start": "Générez des données pour commencer.",
    "existing_items_saved": "éléments existants déjà enregistrés.",
    "samples_failed_to_save": "échantillons non enregistrés. Réessayer peut résoudre les erreurs temporaires.",
    "show_errors": "Afficher les erreurs",
    "hide_errors": "Masquer les erreurs",
    "error_message": "Message d'erreur :",
    "synthetic_data_generation": "Génération de données synthétiques",
    "read_the_docs": "Lire la documentation",
    "save_all": "Tout enregistrer",
    "add_guidance": "Ajouter des conseils",
    "edit_guidance": "Modifier les conseils",
    "save_all_items": "Enregistrer tous les éléments",
    "run_generation": "Exécuter la génération et ajouter au jeu de données.",
    "status": "Statut",
    "items_pending": "éléments en attente",
    "already_saved": "déjà enregistré",
    "human_guidance_enabled": "Conseils activés, mais invite personnalisée fixe détectée. Les conseils ne seront pas appliqués.",
    "human_guidance_warning": "Conseils activés. Vos conseils influenceront la sortie.",
    "run_mode": "Mode d'exécution",
    "parallel_mode": "Parallèle - Idéal pour les API (OpenAI, Fireworks)",
    "sequential_mode": "Séquentiel - Idéal pour Ollama",
    "run_mode_description": "Le mode parallèle est idéal pour les API. Le mode séquentiel convient aux serveurs comme Ollama.",
    "run_and_save": "Exécuter et enregistrer",
    "saved_new_items": "{count} nouveaux éléments enregistrés.",
    "use_dataset_tab": "Utilisez l'onglet",
    "dataset_tab": "jeu de données",
    "to_review_manage": "pour examiner et gérer.",
    "set_tagged_with": "Étiqueter avec \"{tag}\"",
    "complete": "terminé",
    "failed": "échec",
    "content_generation_running": "La génération est en cours. Quitter l'arrêtera.\n\nAnnuler : rester, OK : quitter.",
    "unsaved_changes_warning": "Modifications non enregistrées. Quitter les supprimera.\n\nAnnuler : rester, OK : quitter.",
    "topic_tree_warning": "Votre arborescence de sujets sera perdue si vous quittez.\n\nAnnuler : rester, OK : quitter.",
    "close": "fermer",
    "failed_to_save_sample": "Échec d'enregistrement de l'échantillon",
    "no_id_returned": "Aucun ID renvoyé par le serveur",
    "samples_modal": {
      "title": "Générer des données",
      "subtitle": "Ajouter des échantillons synthétiques",
      "subtitle_to": "à",
      "subtitle_each_subtopic": "chaque sous-thème de",
      "sample_count": "Nombre d'échantillons",
      "failed_to_generate": "Échec de génération pour {topic}. Réessayer peut résoudre le problème.",
      "topics_failed": "{count} thèmes en échec. Réessayer peut résoudre le problème.",
      "generate_samples": "Générer {count} échantillons",
      "for_each_topic": "Pour chaque thème",
      "no_model_selected": "Aucun modèle sélectionné.",
      "invalid_model_selected": "Modèle sélectionné invalide.",
      "no_options_returned": "Aucune option renvoyée.",
      "could_not_generate_topics": "Échec de génération des thèmes. Essayez un autre modèle."
    }
  },
  "evaluation": {
    "title": "Évaluations",
    "page_title": "Évals",
    "page_subtitle": "Évaluer les performances des tâches. Comparer modèles, invites et ajustements fins.",
    "read_docs": "Lire la documentation",
    "new_evaluator": "Nouvel évaluateur",
    "eval_name": "Nom de l'évaluation",
    "description": "Description",
    "selected_run_method": "Méthode d'exécution sélectionnée",
    "model": "Modèle",
    "prompt": "Invite",
    "na": "N/A",
    "unknown_error_occurred": "Erreur inconnue",
    "create_eval": "Créer une évaluation",
    "run_eval": "Exécuter l'évaluation",
    "eval_complete": "Évaluation terminée",
    "eval_complete_with_errors": "Évaluation terminée avec erreurs",
    "running": "Exécution en cours...",
    "no_data_needed": "Aucune donnée à évaluer",
    "compare_eval_methods": "Comparer les méthodes d'évaluation",
    "find_best_evaluator": "Trouver la méthode d'évaluation correspondant le mieux aux évaluations humaines",
    "add_eval_method": "Ajouter une méthode d'évaluation",
    "instructions": "Instructions",
    "select_all_options_error": "Sélectionnez toutes les options nécessaires",
    "re_run_eval": "Ré-exécuter l'évaluation",
    "eval_status": "Statut de l'évaluation",
    "add_more_data_instruction": "Pour ajouter plus de données à votre évaluation,",
    "for_instructions": "pour les instructions",
    "of": "sur",
    "error": "erreur",
    "errors_plural": "s",
    "create_evaluator": {
      "title": "Créer un nouvel évaluateur",
      "subtitle": "Les évaluateurs jugent les performances des tâches.",
      "error_loading_task": "Erreur de chargement des informations de tâche",
      "unknown_error": "Erreur inconnue",
      "part1_title": "Partie 1 : Détails de l'évaluateur",
      "part2_title": "Partie 2 : Scores de sortie",
      "part3_title": "Partie 3 : Jeu de données d'évaluation",
      "part4_title": "Partie 4 : Jeu de données pour comparer les méthodes",
      "evaluator_name": "Nom de l'évaluateur",
      "evaluator_name_description": "Nom identifiant votre évaluateur.",
      "evaluator_description": "Description de l'évaluateur",
      "evaluator_description_description": "Description de votre évaluateur.",
      "output_scores_description": "Définissez les scores que l'évaluateur produira.",
      "template_warning": "Impossible de modifier avec un modèle sélectionné. Utilisez 'Personnalisé' pour créer vos scores.",
      "score_name": "Nom du score",
      "rating_type": "Type d'évaluation",
      "five_star": "5 étoiles",
      "pass_fail": "Réussi/Échoué",
      "pass_fail_critical": "Réussi/Échoué/Critique",
      "instructions": "Instructions",
      "evaluation_dataset": "Jeu de données d'évaluation",
      "evaluation_dataset_description": "Sous-ensemble utilisé pour évaluer les méthodes d'exécution.",
      "evaluation_dataset_info": "Ajoutez l'étiquette suivante aux échantillons :",
      "filter_recommended": "Filtrer avec l'étiquette '{tag}' (recommandé)",
      "filter_custom": "Filtrer par étiquette personnalisée",
      "use_all_data": "Utiliser tous les éléments (non recommandé)",
      "custom_tag_label": "Étiquette de filtre personnalisée",
      "custom_tag_description": "Seuls les éléments avec cette étiquette seront inclus.",
      "eval_method_dataset": "Jeu de données de méthode d'évaluation",
      "eval_method_dataset_description": "Sous-ensemble utilisé pour trouver la meilleure méthode d'évaluation.",
      "eval_method_dataset_info": "Nous recommandons des évaluations humaines pour ce jeu de données.",
      "config_tag_label": "Étiquette de filtre de configuration",
      "config_tag_description": "Filtrage par cette étiquette.",
      "create_evaluator": "Créer l'évaluateur",
      "select_datasets_error": "Sélectionnez les jeux de données d'évaluation et de configuration",
      "output_score": "Score de sortie",
      "select_eval_template": {
        "title": "Sélectionner un modèle d'évaluateur",
        "overall_task_performance": "Performance globale de tâche",
        "overall_task_performance_description": "Évaluer la performance globale via le score global et les objectifs personnalisés.",
        "custom_goal_and_scores": "Objectif et scores personnalisés",
        "create_your_own": "Créer le vôtre",
        "custom_goal_description": "Créez un évaluateur de zéro. Spécifiez scores et instructions.",
        "toxicity_evaluator": "Évaluateur de toxicité",
        "toxicity_description": "Évaluer la toxicité des sorties.",
        "bias_evaluator": "Évaluateur de biais",
        "bias_description": "Détecter les biais de genre, raciaux, etc.",
        "maliciousness_evaluator": "Évaluateur de malveillance",
        "maliciousness_description": "Détecter tromperie, exploitation ou préjudice.",
        "factual_correctness_evaluator": "Évaluateur d'exactitude factuelle",
        "factual_correctness_description": "Vérifier l'exactitude et omissions critiques.",
        "jailbreak_evaluator": "Évaluateur de jailbreak",
        "jailbreak_description": "Détecter les tentatives de contournement d'instructions.",
        "overall_performance_eval": "Évaluation de performance globale",
        "eval_goals_description": "Cette éval évaluera les objectifs suivants :",
        "overall_rating": "Évaluation globale",
        "edit_requirements": "Modifier les exigences",
        "create_eval": "Créer l'évaluation",
        "edit_requirements_note": "Ajoutez/supprimez des objectifs avant de créer votre évaluation.",
        "task_required_error": "Tâche requise, chargement échoué."
      }
    },
    "goals": {
      "define": "Définir les objectifs",
      "create_data": "Créer des données d'évaluation",
      "human_ratings": "Évaluations humaines",
      "find_best_evaluator": "Trouver le meilleur évaluateur",
      "find_best_way": "Trouver la meilleure façon d'exécuter cette tâche"
    },
    "improve_quality": "Améliorer la qualité et accélérer avec les évaluations",
    "create_powerful_evaluators": "Créez des évaluateurs puissants avec des LLM.",
    "compare_approaches": "Comparez rapidement plusieurs approches.",
    "ensure_quality": "Assurez la qualité dans le temps.",
    "evals_guide": "Guide des évaluations",
    "run_with_config": "Exécuter cette évaluation avec la configuration sélectionnée ?",
    "dont_close_page": "Ne fermez pas cette page pour suivre la progression.",
    "considerable_compute": "Cela peut consommer des ressources/credits importants.",
    "task_description": "Description de la tâche :",
    "no_description": "Aucune description fournie.",
    "evaluation_steps": "Étapes d'évaluation :",
    "one_to_five_stars": "1 à 5 étoiles (5 = meilleur)",
    "pass_fail_desc": "0 = échec, 1 = réussi",
    "pass_fail_critical_desc": "-1 = échec critique, 0 = échec, 1 = réussi",
    "main_page": {
      "title": "Éval : {name}",
      "subtitle": "Suivez ces étapes pour trouver la meilleure façon d'évaluer et d'exécuter votre tâche",
      "sub_subtitle": "Lire la documentation",
      "error_loading": "Erreur de chargement de l'évaluateur",
      "unknown_error": "Erreur inconnue",
      "evaluator_properties": "Propriétés de l'évaluateur",
      "name": "Nom",
      "description": "Description",
      "id": "ID",
      "eval_dataset": "Jeu de données d'évaluation",
      "golden_dataset": "Jeu de données de référence",
      "golden_dataset_tooltip": "Utilisé pour évaluer la qualité de la méthode d'évaluation. Doit avoir des évaluations humaines.",
      "eval_algorithm": "Algorithme d'évaluation",
      "eval_algorithm_tooltip": "Algorithme utilisé par votre méthode d'évaluation.",
      "eval_model": "Modèle d'évaluation",
      "eval_model_tooltip": "Modèle utilisé par votre méthode d'évaluation.",
      "run_model": "Modèle d'exécution",
      "run_model_tooltip": "Modèle utilisé par votre méthode d'exécution.",
      "run_prompt": "Invite d'exécution",
      "run_prompt_tooltip": "Invite utilisée par votre méthode d'exécution.",
      "step_titles": {
        "define_goals": "Définir les objectifs",
        "create_eval_data": "Créer des données d'évaluation",
        "human_ratings": "Évaluations humaines",
        "find_best_evaluator": "Trouver le meilleur évaluateur",
        "find_best_way": "Trouver la meilleure façon d'exécuter"
      },
      "step_tooltips": {
        "define_goals": "Chaque évaluation nécessite des objectifs de qualité ('scores d'éval').",
        "create_eval_data": "Deux jeux de données sont nécessaires : un pour l'évaluation, un comme référence ('golden set').",
        "human_ratings": "Un jeu de données 'golden' est évalué par des humains pour valider l'évaluateur.",
        "find_best_evaluator": "Comparez différentes méthodes d'évaluation (modèles, invites, algorithmes).",
        "find_best_way": "Comparez différentes options d'exécution de tâche."
      },
      "goals_description": "Cette éval a {count} objectifs : {goals}.",
      "data_status": {
        "empty": "Créez des données pour cette évaluation.",
        "sufficient": "Vous avez {evalSize} éléments d'évaluation et {goldenSize} éléments de référence.",
        "insufficient": "Données supplémentaires nécessaires. Minimum recommandé : {minSize} éléments par ensemble.",
        "insufficient_eval": "Seulement {evalSize} éléments d'évaluation. Minimum recommandé : {minSize}.",
        "insufficient_golden": "Seulement {goldenSize} éléments de référence. Minimum recommandé : {minSize}."
      },
      "add_eval_data": "Ajouter des données d'évaluation",
      "golden_dataset_status": {
        "empty": "Votre jeu de données de référence est vide.",
        "unrated": "Dans votre jeu de données de référence {issues}. Évaluez tous les éléments.",
        "complete": "Tous les éléments sont entièrement évalués.",
        "unrated_items": "{count} élément{plural} non évalué{verb}",
        "partially_rated_items": "{count} élément{plural} partiellement évalué{verb}"
      },
      "rate_golden_dataset": "Évaluer le jeu de données de référence",
      "view_golden_dataset": "Voir le jeu de données de référence",
      "golden_dataset_filter_note": "Votre jeu de données est filtré par {filter}. Évaluez ces entrées dans l'onglet jeu de données.",
      "eval_method_selected": "Méthode d'évaluation sélectionnée : '{method}' avec le modèle '{model}'.",
      "eval_method_not_selected": "Comparez les évaluations automatisées pour trouver celle correspondant à vos préférences.",
      "compare_eval_methods": "Comparer les méthodes d'évaluation",
      "run_method_selected": "Méthode d'exécution sélectionnée : modèle '{model}' avec l'invite '{prompt}'.",
      "run_method_not_selected": "Comparez modèles, invites et ajustements fins.",
      "compare_run_methods": "Comparer les méthodes d'exécution",
      "creating_eval_progress": {
        "title": "Création d'évaluation",
        "when_done_adding": "Après ajout de données,",
        "when_done_rating": "Après évaluation,",
        "when_done_comparing_eval": "Après comparaison des méthodes d'évaluation,",
        "when_done_comparing_run": "Après comparaison des méthodes d'exécution,",
        "return_to_eval": "retournez à l'évaluation"
      },
      "edit_dialog": {
        "name": "Évaluation",
        "eval_name_label": "Nom de l'évaluation",
        "eval_name_description": "Nom identifiant cette évaluation.",
        "description_label": "Description",
        "description_description": "Description pour vous/votre équipe."
      },
      "errors": {
        "unable_to_add_data": "Impossible d'ajouter des données d'évaluation. Réessayez plus tard.",
        "no_tag_found": "Aucune étiquette trouvée. Configurez manuellement le jeu de données."
      }
    },
    "eval_configs": {
      "title": "Comparer les méthodes d'évaluation",
      "subtitle": "Trouvez la méthode correspondant le mieux aux évaluations humaines",
      "sub_subtitle": "Lire la documentation",
      "error_loading": "Erreur de chargement",
      "unknown_error": "Erreur inconnue",
      "evaluator_properties": "Propriétés de l'évaluateur",
      "name": "Nom",
      "description": "Description",
      "eval_method_dataset": "Jeu de données de méthode d'évaluation",
      "correlation_title": "Corrélation avec les évaluations humaines",
      "correlation_subtitle": "Mesure de corrélation entre la méthode d'évaluation et les évaluations humaines.",
      "score_error": "Erreur inconnue lors de la récupération des scores.",
      "score_label": "Score",
      "score_types": {
        "kendalltau": "Corrélation de Kendall's Tau",
        "spearman": "Corrélation de rang de Spearman",
        "norm_mse": "Erreur quadratique moyenne normalisée",
        "mse": "Erreur quadratique moyenne",
        "norm_mae": "Erreur absolue moyenne normalisée",
        "mae": "Erreur absolue moyenne",
        "pearson": "Corrélation de Pearson"
      },
      "warnings": {
        "issues_to_resolve": "Problèmes à résoudre avant l'analyse.",
        "zero_items": "Aucun élément dans votre jeu de données. Générez des exécutions et étiquetez-les.",
        "not_rated": "{count} élément(s) non évalué(s). Ajoutez des évaluations humaines.",
        "partially_rated": "{count} élément(s) partiellement évalué(s). Évaluez chaque score.",
        "incomplete_evals": "Évaluations incomplètes. Cliquez sur 'Exécuter les évals'.",
        "select_winner": "Cliquez sur 'Définir par défaut' pour sélectionner un gagnant.",
        "small_dataset": "Seulement {size} élément(s). Généralement trop peu pour évaluer les performances."
      },
      "table": {
        "eval_method": "Méthode d'évaluation",
        "eval_method_desc": "Comment la sortie de tâche est évaluée",
        "eval_instructions": "Instructions d'évaluation",
        "method_label": "Méthode :",
        "provider_label": "Fournisseur :",
        "name_label": "Nom :",
        "progress_label": "Progression :",
        "default_badge": "Par défaut",
        "set_as_default": "Définir par défaut",
        "see_all": "Voir tout",
        "none": "Aucun",
        "na_tooltip": "Données insuffisantes pour calculer la corrélation {correlation}. Ajoutez des données manquantes.",
        "no_scores_tooltip": "Aucun score trouvé. Cliquez sur 'Exécuter l'éval' et vérifiez les évaluations humaines."
      },
      "score_tooltips": {
        "mae": "Erreur absolue moyenne. Plus bas = mieux. Pour {rating}.",
        "mse": "Erreur quadratique moyenne. Plus bas = mieux. Pour {rating}.",
        "norm_mse": "Erreur quadratique moyenne normalisée. Plus bas = mieux. Pour {rating}.",
        "norm_mae": "Erreur absolue moyenne normalisée. Plus bas = mieux. Pour {rating}.",
        "spearman": "Corrélation de rang de Spearman. Plus haut = mieux. Pour {rating}.",
        "pearson": "Corrélation de Pearson. Plus haut = mieux. Pour {rating}.",
        "kendalltau": "Corrélation de Kendall's Tau. Plus haut = mieux. Pour {rating}.",
        "five_star": "Évaluation 1 à 5 étoiles",
        "pass_fail": "Évaluation Réussi/Échoué",
        "pass_fail_critical": "Évaluation Réussi/Échoué/Critique"
      },
      "empty_state": {
        "title": "Créez une méthode d'évaluation pour commencer",
        "description": "Une méthode d'évaluation spécifie comment une évaluation est exécutée.",
        "add_button": "Ajouter une méthode d'évaluation"
      },
      "instructions_dialog": {
        "title": "Instructions pour la méthode d'évaluation '{name}'"
      },
      "legend_dialog": {
        "title": "Comment comparer les méthodes d'évaluation",
        "description": "Chaque score mesure la corrélation entre évaluations humaines et scores automatisés.",
        "quick_start_title": "Démarrage rapide",
        "quick_start_1": "Ajoutez diverses méthodes d'évaluation avec différentes options.",
        "quick_start_2": "Utilisez les scores de Kendall's Tau pour comparer (-1.0 à 1.0).",
        "quick_start_3": "Définissez la méthode avec le score Kendall's Tau le plus élevé comme défaut.",
        "detailed_title": "Instructions détaillées",
        "detailed_description": "pour plus d'informations."
      }
    }
  },
  "rating": {
    "pass": "Réussi",
    "fail": "Échoué",
    "critical": "Critique",
    "unrated": "Non évalué",
    "custom_score": "score personnalisé",
    "custom_type_not_supported": "Type personnalisé non supporté dans l'interface"
  },
  "forms": {
    "required": "Obligatoire",
    "optional": "Optionnel",
    "field_required": "{label} est obligatoire",
    "field_too_long": "{label} ne doit pas dépasser {maxLength} caractères",
    "required_field": "Ce champ est obligatoire",
    "invalid_email": "Adresse email invalide",
    "invalid_url": "URL invalide",
    "invalid_number": "Nombre invalide",
    "min_length": "Minimum {min} caractères",
    "max_length": "Maximum {max} caractères",
    "password_mismatch": "Les mots de passe ne correspondent pas",
    "invalid_json": "Format JSON invalide",
    "file_too_large": "Fichier trop volumineux",
    "invalid_file_type": "Type de fichier invalide",
    "unsaved_changes_warning": "Modifications non enregistrées. Quitter les supprimera.\n\nAnnuler : rester, OK : quitter.",
    "please_correct_errors": "Corrigez les erreurs ci-dessus",
    "saved": "Enregistré",
    "form_list": {
      "remove_item_confirm": "Confirmez-vous la suppression de {content_label} #{index} ?",
      "remove": "Retirer",
      "add": "Ajouter {content_label}"
    }
  },
  "progress": {
    "in_progress": "En cours"
  },
  "errors": {
    "eval_id_required": "ID d'évaluation requis",
    "unknown_error": "Erreur inconnue"
  },
  "tooltips": {
    "info": "Information"
  },
  "dialog": {
    "confirm_delete": "Confirmez-vous la suppression ?",
    "cannot_undo": "Action irréversible.",
    "delete_title": "Supprimer {name} ?",
    "delete_confirm_message": "Confirmez-vous la suppression de ce {name} ?",
    "delete_warning": "Sauvegardez votre projet avant de supprimer.",
    "failed_to_delete": "Échec de suppression.",
    "edit_title": "Modifier {name}",
    "save_success": "Enregistrement réussi",
    "save_error": "Échec d'enregistrement"
  },
  "models": {
    "not_tested": "Ce modèle n'a pas été testé avec Kiln. Fonctionnement incertain.",
    "not_recommended_data_gen": "Non recommandé pour la génération de données (génère des données incorrectes).",
    "no_logprobs": "Ne supporte pas les logprobs. Échouera avec les requêtes G-eval.",
    "not_recommended_structured": "Non recommandé pour les sorties structurées (échecs fréquents).",
    "suggest_data_gen": "Pour la génération de données : GPT 4.1, Sonnet, Gemini Pro ou R1.",
    "suggest_evals": "Pour les évaluations : GPT 4.1, Sonnet, Gemini Pro ou R1.",
    "model_label": "Modèle",
    "recommended": "Recommandé",
    "untested_models": "Modèles non testés",
    "not_recommended": "Non recommandé",
    "not_recommended_data_gen_label": "Non recommandé - Génération de données non supportée",
    "not_recommended_structured_label": "Non recommandé - Sortie structurée échoue",
    "not_recommended_logprobs_label": "Non recommandé - Logprobs non supportés"
  },
  "tags": {
    "cannot_be_empty": "Les étiquettes ne peuvent pas être vides",
    "no_spaces": "Pas d'espaces. Utilisez des tirets bas.",
    "add_tag": "Ajouter une étiquette"
  },
  "updates": {
    "check_for_update": "Vérifier les mises à jour",
    "current_version": "Version actuelle",
    "update_available": "Mise à jour disponible",
    "version_available": "est disponible.",
    "download_update": "Télécharger la mise à jour",
    "no_update_available": "Aucune mise à jour disponible",
    "latest_version": "Vous utilisez la dernière version de Kiln.",
    "error_checking": "Erreur de vérification des mises à jour"
  },
  "add_data": {
    "add_samples": "Ajouter des échantillons à votre jeu de données",
    "add_for_eval": "Ajouter des données pour votre évaluation",
    "add_for_finetune": "Ajouter des données pour l'ajustement fin",
    "follow_steps": "Suivez ces étapes pour étiqueter manuellement des données existantes pour votre",
    "adding_tags_proportions": "Étiquettes ajoutées dans les proportions :",
    "synthetic_data": "Données synthétiques",
    "synthetic_data_description": "Générer des données synthétiques avec notre outil interactif.",
    "upload_csv": "Téléverser un CSV",
    "upload_csv_description": "Ajouter des données via un fichier CSV.",
    "manually_run_task": "Exécuter la tâche manuellement",
    "manually_run_task_description": "Chaque exécution sera enregistrée dans votre {reason_name}.",
    "manually_tag_existing_data": "Étiqueter manuellement des données existantes",
    "manually_tag_existing_data_description": "Étiqueter des données existantes pour votre {reason_name}.",
    "data_added": "Données ajoutées",
    "data_added_subtitle": "Vos données ont été ajoutées.",
    "return_to_eval": "Retour à l'évaluation",
    "return_to_finetune": "Retour à l'ajustement fin",
    "view_dataset": "Voir le jeu de données",
    "manually_tag_dialog_title": "Étiqueter manuellement des données existantes",
    "open_dataset": "Ouvrir le jeu de données",
    "dataset_page": "page du jeu de données",
    "follow_steps_to_tag": "Suivez ces étapes pour étiqueter des données existantes pour votre {reason_name}.",
    "step_open_dataset": "Ouvrez le {dataset_link} dans un nouvel onglet.",
    "step_select_data": "Sélectionnez les données à étiqueter avec le bouton \"Sélectionner\".",
    "step_click_tag_single": "Cliquez sur \"Étiqueter\", puis ajoutez l'étiquette \"{tag_name}\".",
    "step_click_tag_multiple": "Cliquez sur \"Étiqueter\", puis ajoutez l'étiquette souhaitée.",
    "step_repeat_for_tags": "Répétez pour chaque étiquette dans les proportions indiquées.",
    "reason_names": {
      "dataset": "jeu de données",
      "eval": "évaluation",
      "fine_tune": "ajustement fin"
    }
  },
  "setup": {
    "welcome_to_kiln": "Bienvenue sur Kiln",
    "easiest_way_to_build": "La façon la plus simple de créer des produits IA",
    "get_started": "Commencer",
    "view_our": "Voir notre",
    "license_agreement": "Contrat de licence",
    "connect_ai_providers": "Connecter des fournisseurs d'IA",
    "connect_providers_subtitle": "Kiln est gratuit, mais nécessite des clés API pour les services IA.",
    "introduction": "Introduction",
    "continue": "Continuer",
    "skip_tutorial": "Passer le tutoriel",
    "newsletter": "Newsletter",
    "newsletter_subtitle": "Zéro spam, désinscription à tout moment, optionnel.",
    "newsletter_description": "Soyez informé des nouvelles fonctionnalités, mises à jour et actualités Kiln AI.",
    "subscribe": "S'abonner",
    "email": "Email",
    "subscribed": "Abonné !",
    "subscribed_message": "Merci pour votre abonnement ! ❤️",
    "continue_without_subscribing": "Continuer sans s'abonner",
    "select_project_and_task": "Sélectionner un projet et une tâche",
    "select_project_and_task_subtitle": "Sélectionnez ou créez un projet et une tâche."
  },
  "providers": {
    "add_models": "Ajouter des modèles",
    "add_model": "Ajouter un modèle",
    "add_new_api": "Ajouter une nouvelle API",
    "manage_providers": "Gérer les fournisseurs & modèles",
    "add_models_subtitle": "Ajoutez des modèles supplémentaires à partir de fournisseurs existants.",
    "saving": "Enregistrement",
    "error_saving_model_list": "Erreur d'enregistrement de la liste de modèles :",
    "add_model_from_provider": "Ajouter un modèle d'un fournisseur existant.",
    "model_id_instructions": "ID exact du modèle utilisé par l'API. Ex: \"gpt-3.5-turbo\" pour OpenAI.",
    "model_provider": "Fournisseur de modèle",
    "model_name": "Nom du modèle",
    "invalid_model_error": "Fournisseur ou nom de modèle invalide.",
    "no_response_error": "Aucune réponse du serveur",
    "settings_not_found": "Paramètres introuvables",
    "connect_providers": {
      "connect": "Connecter",
      "disconnect": "Déconnecter",
      "connected": "Connecté",
      "connecting": "Connexion",
      "manage": "Gérer",
      "cancel": "Annuler",
      "error": "Erreur",
      "reload_page": "Recharger la page",
      "connect_title": "Connecter {provider}",
      "cancel_setup": "Annuler la configuration de {provider}",
      "disconnect_confirm": "Confirmez-vous la déconnexion ? Vos identifiants seront supprimés.",
      "disconnect_failed": "Échec de déconnexion. Erreur inconnue.",
      "ollama_disconnect_message": "Ollama se connecte automatiquement au localhost. Impossible de déconnecter manuellement.",
      "set_custom_ollama_url": "Définir une URL Ollama personnalisée",
      "custom_ollama_url": "URL Ollama personnalisée",
      "custom_ollama_url_description": "Par défaut : http://localhost:11434. Entrez une URL personnalisée ici.",
      "ollama_url_info": "Inclure le préfixe http et le port. Ex: http://localhost:11434",
      "connect_custom_apis": "Connecter des API personnalisées",
      "custom_api_description": "Connectez toute API compatible OpenAI avec une URL de base et une clé API.",
      "existing_apis": "API existantes",
      "add_new_api": "Ajouter une nouvelle API",
      "api_name": "Nom de l'API",
      "api_name_placeholder": "Mon serveur domestique",
      "api_name_info": "Nom identifiant ce point de terminaison.",
      "base_url": "URL de base",
      "base_url_placeholder": "https://.../v1",
      "base_url_info": "URL de base d'une API compatible OpenAI. Ex: https://openrouter.ai/api/v1",
      "api_key": "Clé API",
      "api_key_placeholder": "sk-...",
      "api_key_info": "Clé API pour l'API compatible OpenAI.",
      "base_url_error": "L'URL de base doit commencer par http",
      "remove": "Retirer",
      "remove_provider_failed": "Échec de suppression du fournisseur : {error}",
      "add": "Ajouter",
      "ollama_connected": "Ollama connecté.",
      "ollama_no_supported_models": "Aucun modèle supporté installé -- installez-en (ex: 'ollama pull llama3.1').",
      "ollama_untested_models": "Modèles non testés installés : {models}.",
      "ollama_supported_models": "Modèles supportés disponibles : {models}.",
      "ollama_custom_url": "URL Ollama personnalisée : {url}",
      "ollama_version_error": "Ollama version 0.5.0 ou supérieure requise. Mettez à jour.",
      "ollama_no_models": "Ollama fonctionne, mais aucun modèle disponible. Installez-en.",
      "ollama_connection_failed": "Échec de connexion. Vérifiez que l'application Ollama fonctionne.",
      "provider_descriptions": {
        "openrouter": "Proxy pour OpenAI, Anthropic, etc. Compatible avec presque tous les modèles.",
        "openai": "Chez lui : GPT-4o et plus. Supporte l'ajustement fin.",
        "ollama": "Exécutez des modèles localement. Aucune clé API requise.",
        "groq": "L'hébergeur le plus rapide. Modèles Llama, Gemma et Mistral.",
        "fireworks_ai": "Modèles ouverts (Llama, Phi) + ajustement fin.",
        "anthropic": "Chez lui : Sonnet, Haiku et Opus.",
        "gemini_api": "API Gemini de Google. Ne pas confondre avec Vertex AI.",
        "azure_openai": "API Azure OpenAI de Microsoft.",
        "huggingface": "Plateforme communautaire d'IA avec de nombreux modèles.",
        "vertex": "API Vertex AI de Google. Ne pas confondre avec Gemini AI Studio.",
        "together_ai": "Service d'inférence de Together.ai",
        "amazon_bedrock": "Pour les contrats AWS.",
        "wandb": "Suivez et visualisez vos expériences.",
        "openai_compatible": "Connectez toute API compatible OpenAI."
      },
      "provider_warnings": {
        "openai": "Remarque : l'API OpenAI nécessite un compte distinct de ChatGPT.",
        "azure_openai": "Avec Azure OpenAI, vous devez déployer chaque modèle manuellement.\nDocs : https://docs.getkiln.ai/docs/models-and-ai-providers#azure-openai-api",
        "vertex": "Avec Vertex AI, certains modèles doivent être déployés manuellement.\nDocs : https://docs.getkiln.ai/docs/models-and-ai-providers#google-vertex-ai",
        "amazon_bedrock": "Bedrock est difficile à configurer. Préférez OpenRouter pour plus de simplicité."
      },
      "api_key_steps": {
        "openrouter": [
          "Allez sur https://openrouter.ai/settings/keys",
          "Créez une clé API",
          "Copiez-la et collez-la ci-dessous"
        ],
        "openai": [
          "Créez un compte sur https://platform.openai.com/signup",
          "Allez sur https://platform.openai.com/account/api-keys",
          "Créez une clé secrète",
          "Copiez-la et collez-la ci-dessous"
        ],
        "groq": [
          "Allez sur https://console.groq.com/keys",
          "Créez une clé API",
          "Copiez-la et collez-la ci-dessous"
        ],
        "fireworks_ai": [
          "Allez sur https://fireworks.ai/account/api-keys",
          "Créez une clé API",
          "Allez sur https://fireworks.ai/account/profile",
          "Copiez l'ID de compte et collez-le ci-dessous"
        ],
        "anthropic": [
          "Allez sur https://console.anthropic.com/settings/keys",
          "Créez une clé API",
          "Copiez-la et collez-la ci-dessous"
        ],
        "gemini_api": [
          "Allez sur https://aistudio.google.com/app/apikey",
          "Créez une clé API",
          "Copiez-la et collez-la ci-dessous"
        ],
        "azure_openai": [
          "Ouvrez le portail Azure et naviguez vers votre ressource Azure OpenAI.",
          "Trouvez votre clé API et l'URL du point de terminaison.",
          "Copiez-les et collez-les ci-dessous"
        ],
        "huggingface": [
          "Allez sur https://huggingface.co/settings/tokens",
          "Créez un jeton d'accès",
          "Copiez-le et collez-le ci-dessous"
        ],
        "vertex": [
          "Créez un compte Google Cloud.",
          "Installez le CLI gcloud et exécutez `gcloud auth application-default login`.",
          "Créez un projet dans la console et activez Vertex AI.",
          "Ajoutez l'ID du projet ci-dessous (ID, pas nom).",
          "Ajoutez un emplacement Google Cloud (ex: 'us-central1').",
          "Cliquez sur connecter."
        ],
        "together_ai": [
          "Créez un compte Together.",
          "Créez une clé API : https://api.together.ai/settings/api-keys",
          "Copiez-la et collez-la ci-dessous"
        ],
        "amazon_bedrock": [
          "Allez sur https://us-west-2.console.aws.amazon.com/bedrock/home?region=us-west-2#/overview",
          "Demandez l'accès aux modèles comme Llama et Mistral.",
          "Créez une clé IAM avec la politique 'AmazonBedrockFullAccess'.",
          "Copiez l'ID de clé d'accès et la clé secrète ci-dessous."
        ],
        "wandb": [
          "Créez un compte sur https://wandb.ai ou hébergez votre instance.",
          "Si hébergé localement, définissez l'URL de base ci-dessous.",
          "Si hébergé, obtenez votre clé API sur https://wandb.ai/settings#api.",
          "Cliquez sur 'Connecter'"
        ]
      },
      "api_key_fields": {
        "api_key": "Clé API",
        "account_id": "ID de compte",
        "endpoint_url": "URL du point de terminaison",
        "project_id": "ID du projet",
        "project_location": "Emplacement du projet",
        "access_key": "Clé d'accès",
        "secret_key": "Clé secrète",
        "base_url": "URL de base"
      },
      "pills": {
        "tuneable": "Ajustable"
      }
    }
  },
  "data_generation": {
    "add_top_level_topics": "Ajouter des thèmes principaux",
    "add_top_level_data": "Ajouter des données principales",
    "add_data_to_all": "Ajouter des données à tous",
    "add_subtopics": "Ajouter des sous-thèmes",
    "add_data": "Ajouter des données",
    "add_data_to_all_subtopics": "Ajouter des données à tous",
    "add_custom_topics": "Ajouter des thèmes personnalisés",
    "add_guidance": "Ajouter des conseils",
    "edit_guidance": "Modifier les conseils",
    "human_guidance": "Conseils humains",
    "guidance_description": "Ajoutez des conseils pour améliorer les données générées par l'IA.",
    "guidance_label": "Conseils pour générer des données pertinentes :",
    "clear": "Effacer",
    "done": "Terminé",
    "run_generation": "Exécuter la génération et ajouter au jeu de données.",
    "in_the_docs": "dans la documentation",
    "collapse": "Réduire",
    "expand": "Développer",
    "generate_topics": "Générer des thèmes",
    "topic_count": "Nombre de thèmes",
    "generate_n_topics": "Générer {count} thèmes",
    "custom_topics": "Thèmes personnalisés",
    "comma_separated_list": "Liste séparée par des virgules",
    "add_list_subtopics": "Ajouter une liste de sous-thèmes",
    "to_path": "vers {path}",
    "intro": {
      "synthetic_data_tips": "Conseils pour les données synthétiques",
      "tip_1": "Les thèmes aident à générer des données diversifiées (peuvent être imbriqués).",
      "tip_2": "Les conseils humains améliorent les données générées par l'IA.",
      "guide": "Guide",
      "read_the_docs": "Lire la documentation",
      "generate_title": "Générer des données synthétiques pour l'entraînement ou les évaluations",
      "generate_description": "Recommandé pour créer une évaluation ou un ensemble d'entraînement.",
      "create_eval": "Créer une évaluation",
      "create_finetune": "Créer un ajustement fin",
      "proceed_to_generator": "Passer au générateur"
    }
  },
  "prompts": {
    "page_title": "Invites",
    "page_subtitle": "Invites pour la tâche \"{task_name}\"",
    "page_sub_subtitle": "Lire la documentation",
    "generators_title": "Générateurs d'invites",
    "generators_description": "Les générateurs créent des invites dynamiques basées sur la {task_link} et le {dataset_link}. Ex: l'invite multi-exemples ajoute des échantillons bien notés.",
    "task_default_prompt_link": "invite par défaut de la tâche",
    "task_dataset_link": "jeu de données de la tâche",
    "no_generators_found": "Aucun générateur d'invites trouvé pour cette tâche.",
    "saved_prompts_title": "Invites enregistrées",
    "create_new_prompt_link": "Créer une nouvelle invite",
    "no_saved_prompts_found": "Aucune invite enregistrée. {create_link}.",
    "create_one_now": "Créez-en une maintenant",
    "table_headers": {
      "name": "Nom",
      "description": "Description",
      "name_and_description": "Nom & Description",
      "type": "Type",
      "prompt_preview": "Aperçu de l'invite"
    },
    "prompt_types": {
      "custom": "Personnalisé",
      "fine_tune_prompt": "Invite d'ajustement fin",
      "eval_prompt": "Invite d'évaluation",
      "unknown": "Inconnu"
    },
    "task_link_error": "Ce lien mène aux invites d'une autre tâche. Sélectionnez cette tâche dans la barre latérale.",
    "create_prompt": "Créer une invite",
    "create_prompt_subtitle": "Pour la tâche \"{task_name}\"",
    "prompt_name": "Nom de l'invite",
    "prompt_name_description": "Nom court identifiant cette invite.",
    "prompt_description": "Description de l'invite",
    "prompt_description_description": "Description pour votre référence.",
    "prompt_label": "Invite",
    "prompt_input_description": "Invite à utiliser pour cette tâche.",
    "prompt_info_description": "Une invite LLM comme 'Vous êtes un assistant utile'. Spécifique à cette tâche.",
    "chain_of_thought": "Chaîne de raisonnement",
    "chain_of_thought_description": "Cette invite utilise-t-elle la chaîne de raisonnement ?",
    "chain_of_thought_disabled": "Désactivé",
    "chain_of_thought_enabled": "Activé",
    "chain_of_thought_instructions": "Instructions de chaîne de raisonnement",
    "chain_of_thought_instructions_description": "Instructions pour la 'réflexion' du modèle avant réponse.",
    "chain_of_thought_default": "Réfléchissez étape par étape en expliquant votre raisonnement.",
    "create_prompt_button": "Créer l'invite",
    "generator_details": {
      "title": "Générateur d'invites",
      "generator_description": "Description du générateur",
      "how_to_improve": "Comment améliorer cette invite",
      "improve_description": "Pour améliorer la qualité de cette invite,",
      "edit_task_link_text": "modifiez l'invite/instructions de la tâche",
      "requirements_text": " ou les exigences",
      "additional_improvement": ", ou ajoutez plus d'échantillons de qualité à votre jeu de données en",
      "run_link_text": "exécutant la tâche",
      "additional_improvement_suffix": " et en évaluant/réparant la sortie.",
      "generated_prompt": "Invite générée",
      "generated_prompt_description": "Invite actuelle générée par \"{generator_name}\". Peut changer si votre jeu de données ou définition de tâche évolue.",
      "task_link_error": "Ce lien mène aux invites d'une autre tâche. Sélectionnez cette tâche dans la barre latérale."
    },
    "saved_prompt": {
      "title": "Invite enregistrée",
      "details": "Détails",
      "prompt_not_found": "Invite introuvable.",
      "task_link_error": "Ce lien mène à l'invite d'une autre tâche. Sélectionnez cette tâche dans la barre latérale.",
      "edit_note": "Note : Le contenu de l'invite ne peut pas être modifié pour garantir la cohérence. Copiez cette invite pour créer une nouvelle version.",
      "details_fields": {
        "id": "ID",
        "name": "Nom",
        "description": "Description",
        "created_by": "Créé par",
        "created_at": "Créé le",
        "chain_of_thought": "Chaîne de raisonnement",
        "source_generator": "Générateur source"
      }
    }
  },
  "finetune": {
    "empty_finetune": {
      "title": "L'ajustement fin crée des modèles personnalisés à partir de votre jeu de données",
      "description": "Les modèles ajustés peuvent être plus rapides, moins chers et plus précis.",
      "create_button": "Créer un ajustement fin",
      "guide_button": "Guide d'ajustement fin"
    },
    "select_dataset": "Sélectionner le jeu de données d'ajustement fin",
    "reuse_existing_dataset": "Réutiliser le jeu d'un ajustement fin existant",
    "reuse_existing_description": "Recommandé pour comparer plusieurs modèles de base.",
    "create_new_dataset": "Créer un nouveau jeu de données",
    "create_new_description": "Créez un nouveau jeu en sélectionnant un sous-ensemble de vos données.",
    "add_finetune_data": "Ajouter des données d'ajustement fin",
    "add_data_description": "Ajoutez des données via génération synthétique, téléversement CSV ou étiquetage.",
    "add_additional_data": "ajouter plus de données d'ajustement fin",
    "new_finetune_dataset": "Nouveau jeu de données d'ajustement fin",
    "snapshot_subset": "Capturez un sous-ensemble pour l'ajustement fin.",
    "dataset_filter_tag": "Étiquette de filtre (Obligatoire)",
    "select_tag_description": "Sélectionnez une étiquette. Seuls les échantillons avec cette étiquette seront utilisés.",
    "available_tags_info": "Étiquettes disponibles commençant par 'fine_tune'. Créez des étiquettes personnalisées avec ce préfixe.",
    "filter_reasoning_samples": "Filtrer les échantillons de raisonnement",
    "reasoning_samples_info": "Seuls les échantillons avec des données de réflexion seront inclus. Requis pour les modèles de raisonnement.",
    "filter_highly_rated": "Filtrer les échantillons bien notés",
    "highly_rated_info": "Seuls les échantillons avec 4 ou 5 étoiles seront inclus. Requis pour les modèles de qualité.",
    "advanced_options": "Options avancées",
    "dataset_splits": "Séparation du jeu de données",
    "splits_description": "Définissez les ratios pour séparer les données (entraînement, validation, test).",
    "splits_info": "En cas de doute, utilisez la valeur recommandée.",
    "train_val_80_20": "80% Entraînement, 20% Validation (Recommandé)",
    "train_test_80_10_10": "80% Entraînement, 10% Test, 10% Validation",
    "train_test_val_60_20_20": "60% Entraînement, 20% Test, 20% Validation",
    "train_test_val_80_10_10": "80% Entraînement, 10% Test, 10% Validation",
    "all_training": "100% Entraînement",
    "create_dataset": "Créer le jeu de données",
    "change_dataset": "Modifier le jeu de données",
    "training_dataset_details": "Détails du jeu d'entraînement",
    "dataset_has_splits": "Le jeu sélectionné a {count} {count, plural, one {séparation} other {séparations}} :",
    "split_train": "Utilisé pour l'entraînement",
    "split_val": "Peut être utilisé pour la validation",
    "split_test": "Non utilisé, réservé aux évaluations futures",
    "split_all": "Utilisé pour l'entraînement",
    "examples_count": "{count} exemples",
    "dataset_created": "Jeu de données '{name}' créé {date}",
    "select_existing_dataset": "Sélectionner un jeu d'un ajustement fin existant",
    "select_existing_description": "Utilisez exactement les mêmes données que cet ajustement fin.",
    "no_existing_datasets": "Aucun jeu de données d'ajustement fin trouvé.",
    "dataset_name": "Nom du jeu de données",
    "dataset_size": "Taille du jeu de données",
    "tunes_using_dataset": "Ajustements utilisant ce jeu",
    "in_split": "dans '{split}'",
    "zero_samples_error": "Aucun échantillon correspondant. Votre jeu doit contenir au moins 1 échantillon.",
    "few_samples_warning": "Le jeu n'aura que {count} échantillons. Recommandé : au moins 50.",
    "samples_count_info": "Le jeu aura {count} échantillons.",
    "creating_finetune": "Création d'ajustement fin",
    "when_done_adding": "Après ajout de données,",
    "return_to_finetuning": "retournez à l'ajustement fin",
    "invalid_splits_parameter": "Paramètre de séparation invalide, utilisation par défaut",
    "samples_assigned_tags": "Les échantillons auront les étiquettes : {tags}",
    "create_new_finetune": "Créer un nouvel ajustement fin",
    "finetune_subtitle": "Les modèles ajustés apprennent de votre jeu de données.",
    "step1_title": "Étape 1 : Sélectionner le modèle de base à ajuster",
    "step2_title": "Étape 2 : Sélectionner le jeu de données d'ajustement fin",
    "step3_title": "Étape 3 : Options",
    "step4_title": "Étape 4 : Télécharger JSONL",
    "model_provider_label": "Modèle & Fournisseur",
    "model_provider_description": "Sélectionnez le modèle à ajuster. Ou téléchargez JSONL pour ajuster avec n'importe quelle infrastructure.",
    "model_provider_info": "Connectez des fournisseurs dans les paramètres pour un ajustement en un clic. Ou téléchargez JSONL pour utiliser Unsloth ou Axolotl.",
    "select_model_to_finetune": "Sélectionner un modèle à ajuster",
    "requires_api_key": " --- Requiert une clé API dans les paramètres",
    "connect_providers_warning": "Pour un ajustement en un clic, connectez OpenAI, Fireworks, Together ou Google Vertex.",
    "select_dataset_description": "Sélectionnez un jeu de données pour cet ajustement fin.",
    "dataset_info_tooltip": "Sous-ensemble utilisé pour entraîner et valider le modèle ajusté. Séparé de vos données d'évaluation.",
    "system_prompt_description": "Message système à utiliser pour l'ajustement fin.",
    "system_prompt_info": "Considérations importantes pour choisir un message système. Docs : https://platform.openai.com/docs/guides/fine-tuning/#crafting-prompts",
    "custom_finetune_prompt": "Invite d'ajustement fin personnalisée",
    "custom_system_prompt_label": "Invite système personnalisée",
    "custom_system_prompt_description": "Entrez une invite système personnalisée.",
    "custom_thinking_instructions_label": "Instructions de réflexion personnalisées",
    "custom_thinking_instructions_description": "Instructions pour l'étape de 'réflexion' du modèle.",
    "custom_thinking_instructions_info": "Utilisé lors de l'entraînement avec résultats intermédiaires (raisonnement, etc.).",
    "reasoning_label": "Raisonnement",
    "reasoning_description": "Le modèle doit-il être entraîné sur du contenu de réflexion ?",
    "reasoning_info": "Sélectionnez 'Réflexion' si vous voulez appeler le modèle avec une invite de chaîne de raisonnement.",
    "disabled_recommended": "Désactivé - (Recommandé)",
    "thinking_learn_both": "Réflexion - Apprendre réflexion et réponse finale",
    "thinking_r1_compatible": "Réflexion (compatible R1) - Apprendre réflexion et réponse finale",
    "thinking_dataset_warning": "Vous entraînez un modèle pour la réflexion, mais n'utilisez pas un jeu filtré aux échantillons avec données de raisonnement. Non recommandé.",
    "thinking_r1_warning": "Vous entraînez un modèle 'réflexion', mais n'avez pas sélectionné de jeu filtré aux échantillons avec données de raisonnement. Si vos données contiennent du raisonnement, ignorez cet avertissement.",
    "finetune_name_label": "Nom",
    "finetune_name_description": "Nom identifiant cet ajustement fin. Laissez vide pour un nom généré automatiquement.",
    "finetune_description_label": "Description",
    "finetune_description_description": "Description optionnelle.",
    "hyperparameter_info": "Si incertain, laissez vide pour les valeurs par défaut/recommandées.",
    "start_finetune_job": "Démarrer le travail d'ajustement fin",
    "download_jsonl_description": "Téléchargez JSONL pour ajuster avec n'importe quelle infrastructure comme {unsloth} ou {axolotl}.",
    "download_split": "Télécharger la séparation : {split} ({count} exemples)",
    "error_loading_models": "Erreur de chargement des modèles et jeux de données disponibles",
    "finetune_created_title": "Ajustement fin créé",
    "finetune_created_subtitle": "L'entraînement prendra un certain temps.",
    "view_finetune_job": "Voir le travail d'ajustement fin",
    "invalid_model_provider": "Modèle ou fournisseur invalide",
    "invalid_integer": "Valeur entière invalide pour {name} : {value}",
    "invalid_float": "Valeur flottante invalide pour {name} : {value}",
    "invalid_boolean": "Valeur booléenne invalide : {value}",
    "invalid_hyperparameter_type": "Type d'hyperparamètre invalide : {type}",
    "could_not_create_dataset_split": "Impossible de créer une séparation de jeu de données.",
    "could_not_load_hyperparameters": "Impossible de charger les hyperparamètres.",
    "invalid_response_from_server": "Réponse serveur invalide",
    "type_integer": "Entier",
    "type_float": "Flottant",
    "type_boolean": "Booléen - 'vrai' ou 'faux'",
    "type_string": "Chaîne",
    "download_formats": {
      "openai_chat_jsonl": "Télécharger : Format chat OpenAI (JSONL)",
      "openai_chat_json_schema_jsonl": "Télécharger : Format chat OpenAI avec réponse JSON (JSONL)",
      "openai_chat_toolcall_jsonl": "Télécharger : Format chat OpenAI avec réponse d'appel d'outil (JSONL)",
      "huggingface_chat_template_jsonl": "Télécharger : Modèle de chat HuggingFace (JSONL)",
      "huggingface_chat_template_toolcall_jsonl": "Télécharger : Modèle de chat HuggingFace avec appels d'outil (JSONL)",
      "vertex_gemini": "Télécharger : Format Google Vertex-AI Gemini (JSONL)"
    },
    "details": {
      "title": "Ajustement fin",
      "subtitle": "Ajustez finement des modèles pour la tâche actuelle.",
      "read_docs": "Lire la documentation",
      "create_fine_tune": "Créer un ajustement fin",
      "table_headers": {
        "name": "Nom",
        "type": "Type",
        "provider": "Fournisseur",
        "base_model": "Modèle de base",
        "status": "Statut",
        "created_at": "Créé le"
      },
      "status_values": {
        "pending": "En attente",
        "running": "En cours",
        "completed": "Terminé",
        "failed": "Échec",
        "unknown": "Inconnu"
      },
      "error_loading_finetunes": "Erreur de chargement des ajustements fins",
      "could_not_load_finetunes": "Impossible de charger les ajustements fins. Projet non autorisé.",
      "unknown_error_occurred": "Erreur inconnue",
      "details_section": "Détails",
      "status_section": "Statut",
      "training_prompt_section": "Invite d'entraînement",
      "system_prompt_label": "Invite système",
      "thinking_instructions_label": "Instructions de réflexion",
      "kiln_id": "ID Kiln",
      "name": "Nom",
      "description": "Description",
      "provider": "Fournisseur",
      "base_model": "Modèle de base",
      "model_id": "ID du modèle",
      "job_id": "ID du travail",
      "created_at": "Créé le",
      "created_by": "Créé par",
      "type": "Type",
      "type_info": "Type de modèle déterminé par la stratégie de construction des données d'entraînement.",
      "status": "Statut",
      "status_message": "Message de statut",
      "job_dashboard": "Tableau de bord du travail",
      "dashboard": "Tableau de bord",
      "reload_status": "Recharger le statut",
      "not_completed": "Non terminé",
      "unknown": "Inconnu",
      "error_loading": "Erreur de chargement des modèles et jeux de données",
      "unknown_error": "Erreur inconnue"
    }
  },
  "tutorial": {
    "data_driven_improvements": "Améliorations basées sur les données",
    "data_driven_promo_1": "Évaluez les sorties pour comprendre ce qui fonctionne",
    "data_driven_promo_2": "Exécutez des évaluations pour mesurer les performances",
    "data_driven_promo_3": "Suivez les améliorations avec le contrôle de version",
    "collaborate_team": "Collaborez avec votre équipe",
    "collaborate_promo_1": "Partagez projets et jeux de données",
    "collaborate_promo_2": "Examinez et évaluez ensemble",
    "collaborate_promo_3": "Construisez de meilleurs produits IA en équipe",
    "find_best_way": "Trouvez la meilleure solution",
    "find_best_promo_1": "Comparez différents modèles et fournisseurs",
    "find_best_promo_2": "Testez diverses stratégies d'invites",
    "find_best_promo_3": "Optimisez coût, vitesse et qualité",
    "finetune_synthetic": "Ajustement fin avec données synthétiques",
    "finetune_promo_1": "Générez des données d'entraînement de qualité",
    "finetune_promo_2": "Ajustez des modèles pour votre cas d'usage",
    "finetune_promo_3": "Améliorez au-delà des capacités des invites",
    "library_api": "Bibliothèque et API",
    "library_promo_1": "Intégrez Kiln à votre flux existant",
    "library_promo_2": "Utilisez notre bibliothèque Python ou API REST"
  },
  "test": {
    "project_name": "Projet de test",
    "project_description": "Description de test",
    "user_name": "Utilisateur de test",
    "provider_name": "Fournisseur de test",
    "unknown": "Inconnu"
  },
  "json_schema": {
    "property_number": "Propriété #{number}",
    "remove": "retirer",
    "property_name": "Nom de propriété",
    "type": "Type",
    "required": "Obligatoire",
    "description": "Description",
    "add_property": "Ajouter une propriété",
    "raw_json_schema": "Schéma JSON brut",
    "raw_json_schema_info": "Voir json-schema.org pour la spécification JSON Schema.",
    "revert_to_visual_editor": "Revenir à l'éditeur visuel",
    "not_supported_by_visual_editor": "Non supporté par l'éditeur visuel",
    "switch_to_raw_json_schema": "Passer au schéma JSON brut",
    "switch_to_raw_json_schema_question": "Passer au schéma JSON brut ?",
    "raw_json_schema_description": "Contrôle avancé sur la structure des données (tableaux, objets imbriqués, enums, etc.).",
    "advanced_users_only": "Utilisateurs avancés uniquement",
    "advanced_users_warning": "Fonctionnalités avancées nécessitant une expertise technique. Les schémas invalides causeront des échecs de tâche.",
    "confirm_remove_property": "Confirmez-vous la suppression de la propriété #{number} ?\n\nContenu non enregistré.",
    "confirm_revert_to_visual": "Revenir à l'éditeur visuel ?\n\nModifications du schéma JSON brut perdues.",
    "types": {
      "string": "Chaîne",
      "number": "Nombre",
      "integer": "Entier",
      "boolean": "Booléen",
      "array": "Tableau",
      "object": "Objet",
      "enum": "Enum",
      "other": "Plus..."
    },
    "required_options": {
      "true": "Vrai",
      "false": "Faux"
    },
    "errors": {
      "property_empty": "Propriété vide. Fournissez un nom.",
      "property_special_chars": "Nom de propriété contenant uniquement des caractères spéciaux. Doit être alphanumérique. Nom problématique : {name}",
      "property_not_allowed": "Propriété non autorisée dans JSON schema : {property}",
      "empty_string_non_string": "Chaîne vide pour propriété non-chaîne : {property}",
      "boolean_invalid": "Propriété booléenne doit être 'vrai' ou 'faux' : {property}",
      "integer_invalid": "Propriété {property} doit être un entier : {value}",
      "array_invalid": "Propriété {property} doit être un tableau : {value}",
      "array_json_invalid": "Propriété {property} doit être un tableau JSON valide : {value}",
      "object_invalid": "Propriété {property} doit être un objet JSON valide : {value}",
      "object_json_invalid": "Propriété {property} doit être un objet JSON valide : {value}",
      "unsupported_type": "Type de propriété non supporté : {type} pour {property}.",
      "required_property_missing": "Propriété obligatoire manquante : {property}",
      "schema_validation_failed": "Les données ne correspondent pas au schéma JSON requis.",
      "example_property_title": "Propriété d'exemple",
      "example_property_description": "Remplacez ceci par votre propre propriété"
    }
  },
  "formatters": {
    "unknown": "Inconnu",
    "just_now": "à l'instant",
    "one_minute_ago": "il y a 1 minute",
    "minutes_ago": "il y a minutes",
    "today": "aujourd'hui",
    "eval_config": {
      "g_eval": "G-Eval",
      "llm_as_judge": "LLM en tant que juge"
    },
    "data_strategy": {
      "standard": "Standard",
      "reasoning": "Raisonnement"
    },
    "rating": {
      "five_star": "5 étoiles",
      "pass_fail": "Réussi/Échoué",
      "pass_fail_critical": "Réussi/Échoué/Critique"
    }
  },
  "ui": {
    "fancy_select": {
      "select_option": "Sélectionner une option"
    },
    "warning": {
      "exclamation_icon_alt": "Icône d'avertissement",
      "info_icon_alt": "Icône d'information",
      "check_icon_alt": "Icône de succès"
    }
  },
  "stores": {
    "fine_tune_prompt": "Invite d'ajustement fin",
    "model_id_prefix": "ID du modèle :"
  }
}
